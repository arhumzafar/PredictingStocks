{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import quandl\n",
    "quandl.ApiConfig.api_key = \"K42xtcTyEM7To-P_MwmN\"\n",
    "import torch.nn as nn\n",
    "import torch\n",
    "from torch.autograd import Variable\n",
    "from sklearn.metrics import r2_score\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "DEVICE = torch.device('cuda:1' if torch.cuda.is_available() else 'cpu')\n",
    "# Globals\n",
    "\n",
    "INPUT_SIZE = 60\n",
    "HIDDEN_SIZE = 64\n",
    "NUM_LAYERS = 2\n",
    "OUTPUT_SIZE = 1\n",
    "\n",
    "# Hyper parameters\n",
    "\n",
    "learning_rate = 0.001\n",
    "num_epochs = 50"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing the training set\n",
    "dataset_train = quandl.get(\"WIKI/MSFT\")\n",
    "training_set = dataset_train.iloc[:, 0:1].values\n",
    "\n",
    "# Feature Scaling\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "sc = MinMaxScaler(feature_range = (0, 1))\n",
    "training_set_scaled = sc.fit_transform(training_set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating a data structure with 60 timesteps and 1 output\n",
    "X_train = []\n",
    "y_train = []\n",
    "for i in range(INPUT_SIZE, len(training_set)):\n",
    "    X_train.append(training_set_scaled[i-INPUT_SIZE:i, 0])\n",
    "    y_train.append(training_set_scaled[i, 0])\n",
    "X_train, y_train = np.array(X_train), np.array(y_train)\n",
    "\n",
    "# Reshaping\n",
    "X_train = np.reshape(X_train, (X_train.shape[0], 1, X_train.shape[1])) #1-10, 2-11, 3-12"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "8076"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(training_set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class RNN(nn.Module):\n",
    "    def __init__(self, i_size, h_size, n_layers, o_size):\n",
    "        super(RNN, self).__init__()\n",
    "\n",
    "        self.rnn = nn.LSTM(\n",
    "            input_size=i_size,\n",
    "            hidden_size=h_size,\n",
    "            num_layers=n_layers\n",
    "        )\n",
    "        self.out = nn.Linear(h_size, o_size)\n",
    "\n",
    "    def forward(self, x, h_state):\n",
    "        r_out, hidden_state = self.rnn(x, h_state)\n",
    "        \n",
    "        hidden_size = hidden_state[-1].size(-1)\n",
    "        r_out = r_out.view(-1, hidden_size)\n",
    "        outs = self.out(r_out)\n",
    "\n",
    "        return outs, hidden_state"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "rnn = RNN(INPUT_SIZE, HIDDEN_SIZE, NUM_LAYERS, OUTPUT_SIZE)\n",
    "rnn = rnn.to(DEVICE)\n",
    "optimiser = torch.optim.Adam(rnn.parameters(), lr=learning_rate)\n",
    "criterion = nn.MSELoss()\n",
    "\n",
    "hidden_state = None\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 0, loss 0.06830146908760071\n",
      "epoch 1, loss 0.053515028208494186\n",
      "epoch 2, loss 0.04099605977535248\n",
      "epoch 3, loss 0.030636627227067947\n",
      "epoch 4, loss 0.02289595641195774\n",
      "epoch 5, loss 0.018793592229485512\n",
      "epoch 6, loss 0.01914472132921219\n",
      "epoch 7, loss 0.022127078846096992\n",
      "epoch 8, loss 0.02309488318860531\n",
      "epoch 9, loss 0.020653778687119484\n",
      "epoch 10, loss 0.01679191365838051\n",
      "epoch 11, loss 0.013486858457326889\n",
      "epoch 12, loss 0.011540152132511139\n",
      "epoch 13, loss 0.0107729472219944\n",
      "epoch 14, loss 0.010540085844695568\n",
      "epoch 15, loss 0.010182756930589676\n",
      "epoch 16, loss 0.009295927360653877\n",
      "epoch 17, loss 0.0078317541629076\n",
      "epoch 18, loss 0.006123121362179518\n"
     ]
    }
   ],
   "source": [
    "for epoch in range(num_epochs):\n",
    "    inputs = Variable(torch.from_numpy(X_train).float())\n",
    "    labels = Variable(torch.from_numpy(y_train).float())\n",
    "\n",
    "    output, hidden_state = rnn(inputs, hidden_state) \n",
    "\n",
    "    loss = criterion(output.view(-1), labels)\n",
    "    optimiser.zero_grad()\n",
    "    loss.backward(retain_graph=True)                     # back propagation\n",
    "    optimiser.step()                                     # update the parameters\n",
    "    \n",
    "    print('epoch {}, loss {}'.format(epoch,loss.item()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Getting the real stock price of 2017\n",
    "real_stock_price = dataset_train.iloc[:, 1:2][-365:].values\n",
    "\n",
    "# Getting the predicted stock price of 2017\n",
    "dataset_total = pd.concat((dataset_train['Open'], dataset_train['Open']), axis = 0)\n",
    "inputs = dataset_total[len(dataset_total) - len(real_stock_price) - INPUT_SIZE:].values\n",
    "inputs = inputs.reshape(-1,1)\n",
    "inputs = sc.transform(inputs)\n",
    "X_test = []\n",
    "for i in range(INPUT_SIZE, 420):\n",
    "    X_test.append(inputs[i-INPUT_SIZE:i, 0])  \n",
    "X_test = np.array(X_test)\n",
    "X_test = np.reshape(X_test, (X_test.shape[0], 1, X_test.shape[1]))\n",
    "\n",
    "X_train_X_test = np.concatenate((X_train, X_test),axis=0)\n",
    "hidden_state = None\n",
    "test_inputs = Variable(torch.from_numpy(X_train_X_test).float())\n",
    "predicted_stock_price, b = rnn(test_inputs, hidden_state)\n",
    "predicted_stock_price = np.reshape(predicted_stock_price.detach().numpy(), (test_inputs.shape[0], 1))\n",
    "predicted_stock_price = sc.inverse_transform(predicted_stock_price)\n",
    "\n",
    "real_stock_price_all = np.concatenate((training_set[INPUT_SIZE:], real_stock_price))\n",
    "\n",
    "# Visualising the results\n",
    "plt.figure(1, figsize=(12, 5 ))\n",
    "plt.plot(training_set[-365:], color = 'red', label = 'Real')\n",
    "plt.plot(predicted_stock_price[-365:], color = 'blue', label = 'Pred')\n",
    "plt.title('NVIDIA RNN Stock Price Prediction (2017)')\n",
    "plt.xlabel('Day in 2017')\n",
    "plt.ylabel('NVIDIA Stock Price (USD$)')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Model score\n",
    "score = round(r2_score(training_set[-365:], predicted_stock_price[-365:])*100, 4)\n",
    "accuracy= str(score)\n",
    "print('Training accuracy: ' + accuracy + '%')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "26.046874588639774"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Model MSE\n",
    "MSE = round(mean_absolute_error(predicted_stock_price[-365:], training_set[-365:]), 4)\n",
    "MSE = str(MSE)\n",
    "print('MSE: ' + MSE )"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
